{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN on SnL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports!!\n",
    "\n",
    "## gym\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "## rest\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 55, 53, 15, 50,  7, 31, 81, 14])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = spaces.MultiDiscrete([6]+[101 for _ in range(0, 8)])\n",
    "check.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, symbol):\n",
    "        self.moves = 10\n",
    "        \n",
    "        # player token positions [ 1 - 100 ]\n",
    "        self.pos_token_array = np.zeros(4,)\n",
    "        self.symbol = symbol\n",
    "    \n",
    "    def get_score(self): \n",
    "        score = 0\n",
    "        for token_position in self.pos_token_array:\n",
    "            if token_position == 100:\n",
    "                score += 50\n",
    "            else:\n",
    "                score += token_position\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnlBoard:\n",
    "    \n",
    "    def __init__(self,printing=False):\n",
    "        \n",
    "        self.print_info = printing\n",
    "        \n",
    "        # 100 positions available\n",
    "        # player 2 is a random bot\n",
    "        \n",
    "        self.board = np.zeros(shape=(8,100))\n",
    "        \n",
    "        self.die_val = -1\n",
    "        self.total_positions = 100\n",
    "        self.ties = 0\n",
    "        \n",
    "        self.token_home_reward = 20\n",
    "        self.invalid_move_reward = -50\n",
    "        self.game_won_reward = 100\n",
    "        self.game_lost_reward = 100\n",
    "        self.game_tie_reward = 50\n",
    "        \n",
    "        self.p1_wins = 0\n",
    "        self.p2_wins = 0\n",
    "        \n",
    "        self.opp = {1:2,2:1}\n",
    "        \n",
    "        self.info = dict()\n",
    "        \n",
    "    def reset(self,state):\n",
    "        \"\"\"resets the board to its initial state\n",
    "\n",
    "        Args:\n",
    "            state (_type_): sample from the observation_state [gym space defined for the gym environment] \n",
    "        \"\"\"        \n",
    "        # get initial die value\n",
    "        self.die_val = state[0]  # values [0 - 5]\n",
    "        \n",
    "        # get initial state would always be array(2,4) of zeros\n",
    "        self.board = state[1:].reshape(2,4)\n",
    "        \n",
    "        # board info saved\n",
    "        self.info['starting_state'] = self.board\n",
    "        \n",
    "        self.p1 = Player(1)\n",
    "        self.p2 = Player(2)\n",
    "        \n",
    "        self.info = dict()\n",
    "        \n",
    "        if(self.print_info):\n",
    "            print('################################')\n",
    "            print('environment state:')\n",
    "            print('die value :{}\\nboard state :\\n{}'.format(self.die_val + 1, self.board))\n",
    "            print('player 1 init: ', self.p1)\n",
    "            print('player 2 init: ', self.p2)\n",
    "            print('################################')\n",
    "        \n",
    "     # step for gym environment \n",
    "    \n",
    "    def perform_step(self, action):\n",
    "        \"\"\"perform one step\n",
    "        i.e player 1 plays and then player 2\n",
    "        return board state after this\n",
    "        \"\"\"        \n",
    "        \n",
    "        # reset die value to -1 after p2 turn\n",
    "        if self.die_val == -1:\n",
    "            self.die_val = np.random.randint(0, 6)\n",
    "            \n",
    "        ######## player 1 plays\n",
    "        reward = 0\n",
    "        observation = self.get_board_state()\n",
    "        is_game_end = False\n",
    "        \n",
    "        # action type [VALID | INVALID]\n",
    "        action_type = self.player_plays(self.p1, action)\n",
    "        self.p1.moves += -1\n",
    "        \n",
    "        # in case the action is invalid\n",
    "        if action_type == 'INVALID':                \n",
    "            # get reward\n",
    "            reward = self.invalid_move_reward\n",
    "\n",
    "        if self.print_info:\n",
    "            print('######P1')\n",
    "            print('action :',action)\n",
    "            print('die: ', self.die_val + 1)\n",
    "            print('board state: ', self.get_board_state())\n",
    "            print('p1 score: ', self.p1.get_score())\n",
    "            print('p1 token positions: ', self.p1.pos_token_array)\n",
    "            print('action type: ', action_type)\n",
    "            print('\\n')\n",
    "        \n",
    "        ######## player 2 plays\n",
    "\n",
    "        # roll die\n",
    "        self.die_val = np.random.randint(0,6) # [ 0-5 ]\n",
    "        \n",
    "        # action type does not matter for p2\n",
    "        action_type = self.player_plays(self.p2, np.random.randint(0,4))\n",
    "        self.p2.moves += -1\n",
    "        \n",
    "        if(self.print_info):\n",
    "            print('######P2')\n",
    "            print('die: ', self.die_val + 1)\n",
    "            print('board state: ', self.get_board_state())\n",
    "            print('p2 score: ', self.p2.get_score())\n",
    "            print('p2 token positions: ', self.p2.pos_token_array)\n",
    "            print('\\n')\n",
    "        \n",
    "        ####### setup for gym\n",
    "        \n",
    "        # 1. get final state\n",
    "        self.die_val = np.random.randint(0,6) # [ 0-5 ] die roll for next state\n",
    "        observation = np.concatenate((np.array([self.die_val]), self.get_gym_state())) # observation for next state\n",
    "        \n",
    "        # 2. get final reward\n",
    "        is_game_end = self.game_finished()\n",
    "\n",
    "        if(is_game_end): # rewards given at end of game\n",
    "            reward += self.game_end_rewards()\n",
    "        \n",
    "        score_diff = (self.p1.get_score() - self.p2.get_score())/4 # score diff rewards\n",
    "        \n",
    "        reward += score_diff\n",
    "        \n",
    "        # return step output            \n",
    "        return (observation,reward,is_game_end,{})\n",
    "    \n",
    "    def get_gym_state(self):\n",
    "        return np.concatenate((self.p1.pos_token_array,self.p2.pos_token_array))\n",
    "    \n",
    "    def game_end_info(self):\n",
    "        return self.info\n",
    "        \n",
    "    def is_invalid_move(self, current_position, new_position, active_player:Player):\n",
    "        \n",
    "        # check if new position is out of bounds\n",
    "        if new_position > 100:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def game_end_rewards(self):\n",
    "        p1_won = False\n",
    "        is_tie = False\n",
    "        \n",
    "        if self.p1.get_score() > self.p2.get_score():\n",
    "            p1_won = True\n",
    "        elif self.p1.get_score() == self.p2.get_score():\n",
    "            is_tie = True\n",
    "        \n",
    "        if p1_won:\n",
    "            self.info['p1_won'] = True\n",
    "            self.info['p2_won'] = False\n",
    "            self.info['tie'] = False\n",
    "            \n",
    "            return self.game_won_reward\n",
    "        elif is_tie:\n",
    "            self.info['p1_won'] = False\n",
    "            self.info['p2_won'] = False\n",
    "            self.info['tie'] = True\n",
    "            \n",
    "            return self.game_tie_reward\n",
    "        else:\n",
    "            self.info['p1_won'] = False\n",
    "            self.info['p2_won'] = True\n",
    "            self.info['tie'] = False\n",
    "            \n",
    "            return self.game_lost_reward\n",
    "              \n",
    "    def get_board_state(self):\n",
    "        \"\"\"\n",
    "        get board state\n",
    "        - combination of state and die_val \n",
    "        \"\"\"\n",
    "        # (die value - 1) + (board state)\n",
    "        return np.concatenate((self.p1.pos_token_array.flatten(),self.p2.pos_token_array.flatten()))\n",
    "    \n",
    "    def player_plays(self, active_player:Player, action):        \n",
    "        # player plays turn\n",
    "        token_to_move = action\n",
    "        \n",
    "        # board update state\n",
    "        return self.board_update_after_turn(active_player, token_to_move)\n",
    "          \n",
    "    def board_update_after_turn(self, active_player : Player, token_to_move):\n",
    "        \"\"\" \n",
    "        1. get the new position for the current token\n",
    "        2. check if snakes or ladder\n",
    "        3. update position if 2. is true\n",
    "        4. check if enemy token is already present\n",
    "        5. update enemy position if 4. is true\n",
    "        6. check if self token is already present\n",
    "        7. update position accordingly\n",
    "        Args:\n",
    "            token_symbol (_type_): symbol of token which require updates\n",
    "        \"\"\"\n",
    "                \n",
    "        # 1. get current position of the token from board\n",
    "        \n",
    "        new_token_position = -1\n",
    "        current_token_position = active_player.pos_token_array[token_to_move]\n",
    "        \n",
    "        # get new possible position\n",
    "        new_token_position = current_token_position + (self.die_val + 1) # die value [0,5]\n",
    "\n",
    "        # check if valid position\n",
    "        if(self.is_invalid_move(current_token_position, new_token_position, active_player)):\n",
    "            return 'INVALID'\n",
    "        \n",
    "        \n",
    "        # 2. & 3. update position if snakes or ladder\n",
    "        new_token_position,SnL = self.snake_and_ladder(new_token_position)\n",
    "        \n",
    "        # 4. check if enemy is present\n",
    "        enemy_state, enemy_count = self.enemy_check(new_token_position,active_player)\n",
    "        \n",
    "        # update to new position\n",
    "        active_player.pos_token_array[token_to_move] = new_token_position\n",
    "        # enemy present ? | number of enemy\n",
    "        if enemy_state:\n",
    "            if enemy_count == 1 and new_token_position != 100:\n",
    "                if self.opp[active_player.symbol] == 2:\n",
    "                    mod_index = np.min(np.where(self.p2.pos_token_array == new_token_position))\n",
    "                    self.p2.pos_token_array[mod_index] = 0\n",
    "                else:\n",
    "                    mod_index = np.min(np.where(self.p1.pos_token_array == new_token_position))\n",
    "                    self.p1.pos_token_array[mod_index] = 0\n",
    "        \n",
    "        return 'VALID'\n",
    "         \n",
    "    def enemy_check(self, position, active_player:Player):\n",
    "        \"\"\"checks if an enemy player is present in the position of the moving token\n",
    "\n",
    "        Args:\n",
    "            position (_type_): position on board [1-100]\n",
    "            active_player (Agent): current active player\n",
    "        \"\"\"\n",
    "        enemies = 0\n",
    "        \n",
    "        if (active_player.symbol == 1):\n",
    "            # check if p2 present in position\n",
    "            for pos in self.p2.pos_token_array:\n",
    "                if pos == position:\n",
    "                    enemies += 1\n",
    "        else:\n",
    "            # check if p2 present in position\n",
    "            for pos in self.p1.pos_token_array:\n",
    "                if pos == position:\n",
    "                    enemies += 1\n",
    "\n",
    "        if enemies > 0:\n",
    "            return (True, enemies)\n",
    "        \n",
    "        return (False,enemies)\n",
    "    \n",
    "    def game_finished(self):\n",
    "        \"\"\"check if game finish condition is met\n",
    "        condtion 1 : if the number moves for each player is exhausted\n",
    "        condtion 2 : if any of the player reach 100 before moves are exhausted\n",
    "        \"\"\"\n",
    "        if self.p1.moves == 0 and self.p2.moves == 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def snake_and_ladder(self,position:int):\n",
    "        \"\"\"takes the current position of player and returns the updated position in case of snake or ladder\n",
    "        \"\"\"        \n",
    "        if position in self.get_snakes():\n",
    "            return (self.get_snakes()[position],'snake')\n",
    "        if position in self.get_ladders():\n",
    "            return (self.get_ladders()[position],'ladder')\n",
    "        return (position,'None')\n",
    "    \n",
    "    def get_snakes(self):\n",
    "        snakes = {\n",
    "            99:4,\n",
    "            30:11,\n",
    "            52:29,\n",
    "            70:51,\n",
    "            94:75\n",
    "        }\n",
    "        return snakes\n",
    "    \n",
    "    def get_ladders(self):\n",
    "        ladders = {\n",
    "            3:84,\n",
    "            7:53,\n",
    "            15:96,\n",
    "            21:98,\n",
    "            54:93\n",
    "        }\n",
    "        return ladders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### board test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Board Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **inital state** : [2. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "################################\n",
      "environment state:\n",
      "die value :3.0\n",
      "board state :\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "player 1 init:  <__main__.Player object at 0x12bc8bf10>\n",
      "player 2 init:  <__main__.Player object at 0x16e5fac70>\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "# Snl Board tests\n",
    "board = SnlBoard(printing=True)\n",
    "initital_state = np.concatenate( ( np.array([np.random.randint(0,6)]),np.zeros((2,4)).flatten() ) )\n",
    "\n",
    "# perform reset\n",
    "print('\\n','**inital state** :',initital_state,'\\n')\n",
    "board.reset(initital_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Perform a step action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random_action :  2\n",
      "######P1\n",
      "die:  6.0\n",
      "board state:  [0. 0. 6. 0. 0. 0. 0. 0.]\n",
      "p1 score:  6.0\n",
      "p1 token positions:  [0. 0. 6. 0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  5\n",
      "board state:  [0. 0. 6. 0. 0. 5. 0. 0.]\n",
      "p2 score:  5.0\n",
      "p2 token positions:  [0. 5. 0. 0.]\n",
      "\n",
      "\n",
      "(array([2., 0., 0., 6., 0., 0., 5., 0., 0.]), 0.25, False, {})\n"
     ]
    }
   ],
   "source": [
    "# perform step function\n",
    "random_action = np.random.randint(0,4)\n",
    "print('\\nrandom_action : ',random_action)\n",
    "step_result = board.perform_step(random_action)\n",
    "\n",
    "print(step_result)\n",
    "\n",
    "game_fin = step_result[2]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run a full Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random_action :  1\n",
      "######P1\n",
      "die:  3\n",
      "board state:  [ 0. 84.  6.  0.  0.  5.  0.  0.]\n",
      "p1 score:  90.0\n",
      "p1 token positions:  [ 0. 84.  6.  0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  4\n",
      "board state:  [ 0. 84.  6.  0.  0.  5.  0.  4.]\n",
      "p2 score:  9.0\n",
      "p2 token positions:  [0. 5. 0. 4.]\n",
      "\n",
      "\n",
      "(array([ 5.,  0., 84.,  6.,  0.,  0.,  5.,  0.,  4.]), 20.25, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  1\n",
      "######P1\n",
      "die:  6\n",
      "board state:  [ 0. 90.  6.  0.  0.  5.  0.  4.]\n",
      "p1 score:  96.0\n",
      "p1 token positions:  [ 0. 90.  6.  0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  4\n",
      "board state:  [ 0. 90.  6.  0.  0.  9.  0.  4.]\n",
      "p2 score:  13.0\n",
      "p2 token positions:  [0. 9. 0. 4.]\n",
      "\n",
      "\n",
      "(array([ 5.,  0., 90.,  6.,  0.,  0.,  9.,  0.,  4.]), 20.75, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  2\n",
      "######P1\n",
      "die:  6\n",
      "board state:  [ 0. 90. 12.  0.  0.  9.  0.  4.]\n",
      "p1 score:  102.0\n",
      "p1 token positions:  [ 0. 90. 12.  0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  1\n",
      "board state:  [ 0. 90. 12.  0.  0. 10.  0.  4.]\n",
      "p2 score:  14.0\n",
      "p2 token positions:  [ 0. 10.  0.  4.]\n",
      "\n",
      "\n",
      "(array([ 2.,  0., 90., 12.,  0.,  0., 10.,  0.,  4.]), 22.0, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  2\n",
      "######P1\n",
      "die:  3\n",
      "board state:  [ 0. 90. 96.  0.  0. 10.  0.  4.]\n",
      "p1 score:  186.0\n",
      "p1 token positions:  [ 0. 90. 96.  0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  1\n",
      "board state:  [ 0. 90. 96.  0.  0. 11.  0.  4.]\n",
      "p2 score:  15.0\n",
      "p2 token positions:  [ 0. 11.  0.  4.]\n",
      "\n",
      "\n",
      "(array([ 1.,  0., 90., 96.,  0.,  0., 11.,  0.,  4.]), 42.75, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  1\n",
      "######P1\n",
      "die:  2\n",
      "board state:  [ 0. 92. 96.  0.  0. 11.  0.  4.]\n",
      "p1 score:  188.0\n",
      "p1 token positions:  [ 0. 92. 96.  0.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  1\n",
      "board state:  [ 0. 92. 96.  0.  0. 12.  0.  4.]\n",
      "p2 score:  16.0\n",
      "p2 token positions:  [ 0. 12.  0.  4.]\n",
      "\n",
      "\n",
      "(array([ 0.,  0., 92., 96.,  0.,  0., 12.,  0.,  4.]), 43.0, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  3\n",
      "######P1\n",
      "die:  1\n",
      "board state:  [ 0. 92. 96.  1.  0. 12.  0.  4.]\n",
      "p1 score:  189.0\n",
      "p1 token positions:  [ 0. 92. 96.  1.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  5\n",
      "board state:  [ 0. 92. 96.  1.  0. 12.  5.  4.]\n",
      "p2 score:  21.0\n",
      "p2 token positions:  [ 0. 12.  5.  4.]\n",
      "\n",
      "\n",
      "(array([ 2.,  0., 92., 96.,  1.,  0., 12.,  5.,  4.]), 42.0, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  3\n",
      "######P1\n",
      "die:  3\n",
      "board state:  [ 0. 92. 96.  4.  0. 12.  5.  0.]\n",
      "p1 score:  192.0\n",
      "p1 token positions:  [ 0. 92. 96.  4.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  1\n",
      "board state:  [ 0. 92. 96.  4.  0. 12.  5.  1.]\n",
      "p2 score:  18.0\n",
      "p2 token positions:  [ 0. 12.  5.  1.]\n",
      "\n",
      "\n",
      "(array([ 4.,  0., 92., 96.,  4.,  0., 12.,  5.,  1.]), 43.5, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  2\n",
      "######P1\n",
      "die:  5\n",
      "board state:  [ 0. 92. 96.  4.  0. 12.  5.  1.]\n",
      "p1 score:  192.0\n",
      "p1 token positions:  [ 0. 92. 96.  4.]\n",
      "action type:  INVALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  6\n",
      "board state:  [ 0. 92. 96.  4.  0. 12. 11.  1.]\n",
      "p2 score:  24.0\n",
      "p2 token positions:  [ 0. 12. 11.  1.]\n",
      "\n",
      "\n",
      "(array([ 1.,  0., 92., 96.,  4.,  0., 12., 11.,  1.]), -8.0, False, {})\n",
      "################################################################\n",
      "\n",
      "random_action :  3\n",
      "######P1\n",
      "die:  2\n",
      "board state:  [ 0. 92. 96.  6.  0. 12. 11.  1.]\n",
      "p1 score:  194.0\n",
      "p1 token positions:  [ 0. 92. 96.  6.]\n",
      "action type:  VALID\n",
      "\n",
      "\n",
      "######P2\n",
      "die:  4\n",
      "board state:  [ 0. 92.  0.  6.  0. 12. 96.  1.]\n",
      "p2 score:  109.0\n",
      "p2 token positions:  [ 0. 12. 96.  1.]\n",
      "\n",
      "\n",
      "(array([ 3.,  0., 92.,  0.,  6.,  0., 12., 96.,  1.]), 97.25, True, {})\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "# perform a game loop\n",
    "while not game_fin: # game finished state\n",
    "    random_action = np.random.randint(0,4)\n",
    "    print('\\nrandom_action : ',random_action)\n",
    "    step_result = board.perform_step(random_action)\n",
    "    print(step_result)\n",
    "    print('################################################################')\n",
    "    game_fin = step_result[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup GYM environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "class SNL_env(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, printing=False):\n",
    "        super().__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        ## 8 [total tokens] * 100 [positions]\n",
    "        self.observation_space = spaces.MultiDiscrete([6]+[101 for _ in range(0, 8)])\n",
    "        self.SNLBoard = SnlBoard(printing)\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        # player 1 plays\n",
    "        # player 2 plays\n",
    "        # new state is observed\n",
    "        # reward is calculated\n",
    "        # check if game is completed\n",
    "        # info is optional\n",
    "        \n",
    "        observation, reward, done, info = self.SNLBoard.perform_step(action)\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        # initializing state\n",
    "        state = np.concatenate(([np.random.randint(0,6)],np.zeros(shape=(2,4)).flatten()))\n",
    "        \n",
    "        # reset board | set inital state\n",
    "        self.SNLBoard.reset(state)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "\n",
    "    def render(self, mode='console'):\n",
    "        if mode != 'console':\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        return self.SNLBoard.game_end_info()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C,PPO,\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Instantiate the env\n",
    "env = SNL_env()\n",
    "# check environment validity\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the env\n",
    "env = SNL_env()\n",
    "# Define and Train the agent\n",
    "model = A2C(policy='MlpPolicy',env=env).learn(total_timesteps=1000000)\n",
    "model.save(\"A2CMlP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the env\n",
    "env = SNL_env()\n",
    "# Define and Train the agent\n",
    "model = PPO(policy='MlpPolicy',env=env).learn(total_timesteps=1000000)\n",
    "model.save(\"PPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultiDiscrete** _observation space_ for SnL \n",
    "\n",
    "**Discrete** _action space_ for SnL [only 4 actions are allowed]\n",
    "\n",
    "- state representation will be as follows:\n",
    "\n",
    "    [\n",
    "        [0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0] ..... ..... x 100\n",
    "    ]\n",
    "\n",
    "- reward should be very bad for an illegal action\n",
    "- reward should be given proportionally to the difference of score between the players [handles snake and ladder case as well]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 0, 0, 0, 1, 1, 2,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 1, 0, 0, 1, 0,\n",
       "       2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "       2, 1, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 1, 2, 0,\n",
       "       0, 2, 1, 0, 0, 2, 0, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 1, 2, 0, 0, 1,\n",
       "       1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 2, 1,\n",
       "       0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2,\n",
       "       0, 2, 1, 2, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1,\n",
       "       1, 2, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 0, 0,\n",
       "       0, 2, 0, 1, 1, 0, 2, 1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0,\n",
       "       1, 0, 0, 0, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 2, 2, 2, 2, 0,\n",
       "       1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 2, 2, 2, 2,\n",
       "       0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 0, 1,\n",
       "       1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1,\n",
       "       0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 2, 0, 1, 1, 1, 2, 1,\n",
       "       0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 2, 2,\n",
       "       0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 0, 2, 1, 1, 0, 2, 2,\n",
       "       0, 1, 0, 0, 1, 1, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0,\n",
       "       1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 1, 0,\n",
       "       0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1, 2, 0, 2,\n",
       "       0, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 2, 1, 0, 1,\n",
       "       2, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 2,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1,\n",
       "       1, 1, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0,\n",
       "       2, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 1,\n",
       "       2, 1, 0, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 0, 2, 0, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation space for SnL\n",
    "observation_space = spaces.MultiDiscrete([6]+[3 for _ in range(0, 800)])\n",
    "observation_space.sample()\n",
    "\n",
    "# action space for SnL\n",
    "# action_space = spaces.Discrete(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f7a3e848c8227b89d664180b9ceb0de262ee40507351cc8d8d85dc5a7f5602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
