{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN on SnL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports!!\n",
    "\n",
    "## gym\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "## rest\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, token):\n",
    "        self.moves = 10\n",
    "        \n",
    "        # player token positions [ 1 - 100 ]\n",
    "        self.post_token_array = np.zeros(4,)\n",
    "    \n",
    "    def get_score(self): \n",
    "        score = 0\n",
    "        for token_position in self.post_token_array:\n",
    "            if token_position == 100:\n",
    "                score += 50\n",
    "            else:\n",
    "                score += token_position\n",
    "\n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSnlBoard\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \n\u001b[1;32m      5\u001b[0m         \u001b[39m# 100 positions available\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[39m# player 2 is a random bot\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m,\u001b[39m8\u001b[39m))\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mSnlBoard\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer_plays(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp1)\n\u001b[1;32m     39\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer_plays(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp2)\n\u001b[0;32m---> 43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplayer_plays\u001b[39m(\u001b[39mself\u001b[39m, active_player:Agent):\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdie_val \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m,\u001b[39m6\u001b[39m)\n\u001b[1;32m     47\u001b[0m     inital_score \u001b[39m=\u001b[39m active_player\u001b[39m.\u001b[39mscore\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Agent' is not defined"
     ]
    }
   ],
   "source": [
    "class SnlBoard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # 100 positions available\n",
    "        # player 2 is a random bot\n",
    "        \n",
    "        self.board = np.zeros(shape=(100,8))\n",
    "        \n",
    "        self.die_val = -1\n",
    "        self.total_positions = 100\n",
    "        self.ties = 0\n",
    "        \n",
    "        self.p1 = Player()\n",
    "        self.p2 = Player()\n",
    "        \n",
    "        player_tokens = {self.p1 : 1, self.p2 : 1}\n",
    "        \n",
    "        self.info = dict()\n",
    "    \n",
    "    # reset for gym environment\n",
    "    def reset(self,state):\n",
    "        \n",
    "        # get initial die value\n",
    "        self.die_val = state[0]  # values [0 - 5]\n",
    "        \n",
    "        # get initial state would always be array(800,) of zeros\n",
    "        self.board = state[1:].reshape(100,8)\n",
    "        \n",
    "        # board info saved\n",
    "        self.info['starting_state'] = self.board\n",
    "        \n",
    "        \n",
    "     # step for gym environment \n",
    "    def perform_step(self, action):\n",
    "        \"\"\"perform one step\n",
    "        i.e player 1 plays and then player 2\n",
    "        return board state after this\n",
    "        \"\"\"        \n",
    "        \n",
    "        # reset die value to -1 after p2 turn\n",
    "        if self.die_val != -1:\n",
    "            self.die_val = np.random.randint(0, 6)\n",
    "        \n",
    "        while not self.game_finished():\n",
    "            self.player_plays(self.p1, action)\n",
    "            \n",
    "        pass\n",
    "\n",
    "    \n",
    "    def is_invalid_move(self):\n",
    "        pass\n",
    "    \n",
    "    def get_board_state(self):\n",
    "        \"\"\"\n",
    "        get board state\n",
    "        - combination of state and die_val\n",
    "        \"\"\"\n",
    "        # (die value - 1) + (board state)\n",
    "        return np.concatenate((np.array([self.die_val]),self.board.flatten()))\n",
    "\n",
    "\n",
    "\n",
    "    def player_plays(self, active_player:Player, action):\n",
    "            \n",
    "        inital_score = active_player.get_score()\n",
    "        original_state = self.get_board_state()\n",
    "        \n",
    "        \n",
    "        # player plays turn\n",
    "        token_to_move = action\n",
    "        \n",
    "        \n",
    "        # implement strategies if applicable\n",
    "        \n",
    "        # if active_player.AGENT_TYPE == 'RL' and self.isTrain:\n",
    "        #     token_to_move_strat = self.check_stratergies(self.board, active_player)        \n",
    "        #     if token_to_move_strat:\n",
    "        #         token_to_move = token_to_move_strat\n",
    "        \n",
    "        \n",
    "        # board update state\n",
    "        while not self.board_update_after_turn(active_player.symbol+'_'+str(token_to_move), active_player):\n",
    "            token_to_move = active_player.play_turn(self.getStateHash(),(self.die_val - 1))\n",
    "        \n",
    "        if active_player.AGENT_TYPE == 'RL':\n",
    "            # get reward for action\n",
    "            reward = self.calculate_reward(active_player,inital_score)\n",
    "            \n",
    "            # update q value\n",
    "            active_player.update_Q_val(self.getStateHash(),original_state,token_to_move,(self.die_val - 1), reward)\n",
    "        \n",
    "        active_player.moves -= 1\n",
    "   \n",
    "   \n",
    "   \n",
    "    def board_update_after_turn(self, token_symbol, active_player : Player):\n",
    "        \"\"\" \n",
    "        1. get the new position for the current token\n",
    "        2. check if snakes or ladder\n",
    "        3. update position if 2. is true\n",
    "        4. check if enemy token is already present\n",
    "        5. update enemy position if 4. is true\n",
    "        6. check if self token is already present\n",
    "        7. update position accordingly\n",
    "        Args:\n",
    "            token_symbol (_type_): symbol of token which require updates\n",
    "        \"\"\"\n",
    "                \n",
    "        # 1. get current position of the token from board\n",
    "        new_position = -1\n",
    "        \n",
    "        # token found ? | token position | token location\n",
    "        token_state = self.token_on_board(token_symbol)\n",
    "        \n",
    "        if token_state[0]:\n",
    "            new_position = token_state[1] + self.die_val\n",
    "            # remove token from the old position\n",
    "            self.board[token_state[1]].remove(token_symbol)\n",
    "        else:\n",
    "            new_position += self.die_val\n",
    "        \n",
    "        # is token position valid?\n",
    "        if new_position > self.total_positions - 1:\n",
    "            return False\n",
    "        \n",
    "        # 2. & 3. update position if snakes or ladder\n",
    "        new_position,SnL = self.snake_and_ladder(new_position + 1) \n",
    "        new_position -= 1 # +1 -1 for the correct index\n",
    "        \n",
    "        if SnL == 'snake':\n",
    "            active_player.snake_cut = True\n",
    "        if SnL == 'ladder':\n",
    "            active_player.ladder_climb = True\n",
    "        \n",
    "        # 4. check if enemy is present\n",
    "        enemy_state = self.enemy_check(new_position,active_player)\n",
    "        # enemy present ? | number of enemy\n",
    "        if enemy_state[0]:\n",
    "            if enemy_state[1] > 1:\n",
    "                # in case of multiple enemy\n",
    "                self.board[new_position].append(token_symbol)\n",
    "            else:\n",
    "                self.update_enemy_token(new_position,self.p1)\n",
    "                active_player.number_of_tokens_cut += 1\n",
    "        else:\n",
    "            self.board[new_position].append(token_symbol)\n",
    "            pass\n",
    "        # update score based on new token positions\n",
    "        self.update_player_scores()\n",
    "        \n",
    "        return True\n",
    "       \n",
    "    def calculate_reward(self,active_player, original_score):\n",
    "        \"\"\"calcualtes reward base on actions taken\n",
    "\n",
    "        Args:\n",
    "            active_player (Agent): cuurent active player\n",
    "        \"\"\"\n",
    "\n",
    "        if active_player.symbol == 'P1':\n",
    "            opponent = self.p2\n",
    "        else: \n",
    "            opponent = self.p1\n",
    "\n",
    "       \n",
    "        # score diff reward\n",
    "        score_diff_reward = active_player.score - opponent.score\n",
    "        \n",
    "        # snake or ladder reward\n",
    "        snl_reward = 0\n",
    "        if active_player.snake_cut:\n",
    "            snl_reward += active_player.score - original_score\n",
    "            active_player.snake_cut = False\n",
    "        if active_player.ladder_climb:\n",
    "            snl_reward += active_player.score - original_score\n",
    "            active_player.ladder_climb = False\n",
    "        \n",
    "        # reward on token cut?\n",
    "        token_cut_reward = 0\n",
    "        if active_player.has_cut_token:\n",
    "            # fixed reward of 200\n",
    "            token_cut_reward = 200\n",
    "            active_player.has_cut_token = False\n",
    "        \n",
    "        return (token_cut_reward + score_diff_reward + snl_reward)/100\n",
    "\n",
    "    def update_player_scores(self):        \n",
    "        p1_score = 0\n",
    "        p2_score = 0\n",
    "        for idx, position in enumerate(self.board):\n",
    "            for token in position:\n",
    "                \n",
    "                if token in self.p1.player_tokens:\n",
    "                    p1_score += self.board.index(position) + 1\n",
    "                    if idx == 99: # if token has reached the end then extra points\n",
    "                        p1_score += 100\n",
    "                if token in self.p2.player_tokens:\n",
    "                    p2_score += self.board.index(position) + 1\n",
    "                    if idx == 99:\n",
    "                        p2_score += 100\n",
    "        \n",
    "        self.p1.score = p1_score\n",
    "        self.p2.score = p2_score    \n",
    "        \n",
    "    def token_on_board(self, token_symbol):\n",
    "        for position in self.board:\n",
    "            if token_symbol in position:\n",
    "                return (True,self.board.index(position),position.index(token_symbol)) # (true,position_index,token_index)\n",
    "        return (False,-1,-1)\n",
    "\n",
    "    def enemy_check(self, position, active_player):\n",
    "        \"\"\"checks if an enemy player is present in the position of the moving token\n",
    "\n",
    "        Args:\n",
    "            position (_type_): _description_\n",
    "            active_player (Agent): _description_\n",
    "        \"\"\"        \n",
    "        enemy_present = False\n",
    "        enemy_count = 0\n",
    "        for token in self.board[position]:\n",
    "            if token[0:2] != active_player.symbol:\n",
    "                enemy_count += 1\n",
    "                enemy_present = True\n",
    "        return(enemy_present, enemy_count)\n",
    "    \n",
    "    def update_enemy_token(self,position, active_player):\n",
    "        \"\"\"cuts the enemy player and updates scores\n",
    "\n",
    "        Args:\n",
    "            position (_type_): _description_\n",
    "            active_player (Agent): _description_\n",
    "        \"\"\"        \n",
    "        # update enemy position\n",
    "        self.board[position].pop()\n",
    "        # update enemy score\n",
    "        if active_player.symbol == 'P1':\n",
    "            self.p2.score -= position + 1\n",
    "        if active_player.symbol == 'P2':\n",
    "            self.p1.score -= position + 1\n",
    "            \n",
    "        # update that active player has cut enemy token\n",
    "        active_player.has_cut_token = True\n",
    "\n",
    "    def game_finished(self):\n",
    "        \"\"\"check if game finish condition is met\n",
    "        condtion 1 : if the number moves for each player is exhausted\n",
    "        condtion 2 : if any of the player reach 100 before moves are exhausted\n",
    "        \"\"\"\n",
    "        if self.p1.moves == 0 and self.p2.moves == 0:\n",
    "            if self.p1.score > self.p2.score:\n",
    "                self.p1_wins += 1\n",
    "            elif self.p1.score < self.p2.score:\n",
    "                self.p2_wins += 1\n",
    "            else:\n",
    "                self.ties += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def snake_and_ladder(self,position:int):\n",
    "        \"\"\"takes the current position of player and returns the updated position in case of snake or ladder\n",
    "        \"\"\"        \n",
    "        if position in self.get_snakes():\n",
    "            return (self.get_snakes()[position],'snake')\n",
    "        if position in self.get_ladders():\n",
    "            return (self.get_ladders()[position],'ladder')\n",
    "        return (position,'None')\n",
    "    \n",
    "    def get_snakes(self):\n",
    "        snakes = {\n",
    "            99:4,\n",
    "            30:11,\n",
    "            52:29,\n",
    "            70:51,\n",
    "            94:75\n",
    "        }\n",
    "        return snakes\n",
    "    \n",
    "    def get_ladders(self):\n",
    "        ladders = {\n",
    "            3:84,\n",
    "            7:53,\n",
    "            15:96,\n",
    "            21:98,\n",
    "            54:93\n",
    "        }\n",
    "        return ladders\n",
    "    \n",
    "    def reset(self):\n",
    "        self.p1.reset()\n",
    "        self.p2.reset()\n",
    "        self.board = [[] for _ in range(self.total_positions)]\n",
    "    \n",
    "    def get_board():\n",
    "        pass\n",
    "\n",
    "    ####utilities#######################################################\n",
    "    \n",
    "    def savePolicy(self,active_player):\n",
    "        fw = open('./snl_rl/STATE_VALUE IMPLEMENTATION/a_one/policies/policy_' + str(active_player.symbol), 'wb')\n",
    "        pickle.dump(active_player.Q_val, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file, active_player):\n",
    "        fr = open(file, 'rb')\n",
    "        active_player.Q_val = pickle.load(fr)\n",
    "        fr.close()\n",
    "\n",
    "    def get_stats(self):\n",
    "        print('p1 wins : ',self.p1_wins)\n",
    "        print('p1 token cuts : ',self.p1.number_of_tokens_cut)\n",
    "        print('p2 wins : ',self.p2_wins)\n",
    "        print('p1 win/ratio : ',self.p1_wins/self.p2_wins)\n",
    "        print('ties : ',self.ties)\n",
    "\n",
    "    ####strats###########################################################\n",
    "    \n",
    "    def check_stratergies(self, board, active_player):\n",
    "        \n",
    "        strat = BoardStrats(board, active_player,self.die_val)\n",
    "        ladder_token = strat.best_ladder_token()\n",
    "        \n",
    "        enemy_cut_token = strat.best_enemy_cut_token()\n",
    "\n",
    "        if enemy_cut_token:\n",
    "            return enemy_cut_token\n",
    "        \n",
    "        if ladder_token:\n",
    "            return ladder_token\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "class snl_env(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        ## 8 [total tokens] * 100 [positions]\n",
    "        self.observation_space = spaces.MultiDiscrete([6]+[3 for _ in range(0, 800)])\n",
    "        \n",
    "        self.rng = self.np_random\n",
    "\n",
    "    def step(self, action):\n",
    "        # player 1 plays\n",
    "        # player 2 plays\n",
    "        # new state is observed\n",
    "        # reward is calculated\n",
    "        # check if game is completed\n",
    "        # info is optional\n",
    "        \n",
    "        observation, reward, done, info = self.SNLBoard.perform_step(action)\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        # initializing state\n",
    "        state = np.concatenate(([np.random.randint(0,6)],np.zeros(shape=(100,8)).flatten()))\n",
    "        \n",
    "        # reset board | set inital state\n",
    "        self.SNLBoard = SnlBoard().reset(state)\n",
    "        \n",
    "        # set inital state\n",
    "        self.current_obs = state\n",
    "        \n",
    "        return self.current_obs\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        ...\n",
    "\n",
    "    def close(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_ = spaces.Box(low=0,high=2,shape=(3,3))\n",
    "box_ = spaces.Discrete(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultiDiscrete** _observation space_ for SnL \n",
    "\n",
    "**Discrete** _action space_ for SnL [only 4 actions are allowed]\n",
    "\n",
    "- state representation will be as follows:\n",
    "\n",
    "    [\n",
    "        [0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0] ..... ..... x 100\n",
    "    ]\n",
    "\n",
    "- reward should be very bad for an illegal action\n",
    "- reward should be given proportionally to the difference of score between the players [handles snake and ladder case as well]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 0, 0, 0, 1, 1, 2,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 1, 0, 0, 1, 0,\n",
       "       2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "       2, 1, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 1, 2, 0,\n",
       "       0, 2, 1, 0, 0, 2, 0, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 1, 2, 0, 0, 1,\n",
       "       1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 2, 1,\n",
       "       0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2,\n",
       "       0, 2, 1, 2, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1,\n",
       "       1, 2, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 0, 0,\n",
       "       0, 2, 0, 1, 1, 0, 2, 1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0,\n",
       "       1, 0, 0, 0, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 2, 2, 2, 2, 0,\n",
       "       1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 2, 2, 2, 2,\n",
       "       0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 0, 1,\n",
       "       1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1,\n",
       "       0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 2, 0, 1, 1, 1, 2, 1,\n",
       "       0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 2, 2,\n",
       "       0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 0, 2, 1, 1, 0, 2, 2,\n",
       "       0, 1, 0, 0, 1, 1, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0,\n",
       "       1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 1, 0,\n",
       "       0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1, 2, 0, 2,\n",
       "       0, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 2, 1, 0, 1,\n",
       "       2, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 2,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1,\n",
       "       1, 1, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0,\n",
       "       2, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 1,\n",
       "       2, 1, 0, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 0, 2, 0, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation space for SnL\n",
    "observation_space = spaces.MultiDiscrete([6]+[3 for _ in range(0, 800)])\n",
    "observation_space.sample()\n",
    "\n",
    "# action space for SnL\n",
    "# action_space = spaces.Discrete(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f7a3e848c8227b89d664180b9ceb0de262ee40507351cc8d8d85dc5a7f5602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
